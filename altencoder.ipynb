{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset members have the following lengths: {1158, 294} (expected 294)\n",
      "Has 1 corrupt value(s), 601 values, 601 keys\n",
      "dataset size: (601, 294)\n",
      "partitioning as train = (500, 294), test = (101, 294)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import urllib\n",
    "import zipfile\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "SW_DATASET_URL = 'https://github.com/SeijiEmery/shape-net-data/raw/master/car-vertex-data/shrinkwrap-data.json.zip'\n",
    "with urllib.request.urlopen(SW_DATASET_URL) as f:\n",
    "    with zipfile.ZipFile(io.BytesIO(f.read()), 'r') as zf:\n",
    "        with zf.open('shrinkwrap-data.json', 'r') as f:\n",
    "            sw_dataset = json.loads(f.read())\n",
    "            \n",
    "sw_keys = list(sw_dataset.keys())\n",
    "sw_dimensions = set(map(len, sw_dataset.values()))\n",
    "print(\"dataset members have the following lengths: %s (expected 294)\"%(sw_dimensions,))\n",
    "\n",
    "sw_keys = [ key for key in sw_dataset.keys() if len(sw_dataset[key]) == 294 ]\n",
    "non_corrupt_values = [ x for x in sw_dataset.values() if len(x) == 294 ]\n",
    "corrupt_values = [ x for x in sw_dataset.values() if len(x) != 294 ]\n",
    "print(\"Has %s corrupt value(s), %s values, %s keys\"%(\n",
    "    len(corrupt_values), len(non_corrupt_values), len(sw_keys)))\n",
    "\n",
    "sw_data = np.array(non_corrupt_values)\n",
    "print(\"dataset size: %s\"%(sw_data.shape,))\n",
    "\n",
    "x_train, x_test = np.split(sw_data, [500], 0)\n",
    "print(\"partitioning as train = %s, test = %s\"%(x_train.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 80)                23600     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                810       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 80)                880       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 294)               23814     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 294)               0         \n",
      "=================================================================\n",
      "Total params: 49,104\n",
      "Trainable params: 49,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.models import Model, load_model\n",
    "import os\n",
    "\n",
    "INPUT_DIM = 294\n",
    "HIDDEN_DIM = 80\n",
    "LATENT_DIM = 10\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(HIDDEN_DIM, input_shape=(INPUT_DIM,)),\n",
    "    Activation('relu'),\n",
    "    Dense(LATENT_DIM),\n",
    "    Activation('relu'),\n",
    "    Dense(HIDDEN_DIM),\n",
    "    Activation('relu'),\n",
    "    Dense(INPUT_DIM),\n",
    "    Activation('linear')\n",
    "])\n",
    "trained_epochs = 0\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "def train (epochs, batch_size=50):\n",
    "    global model, trained_epochs\n",
    "    print(\"Training: epoch %s -> %s\"%(trained_epochs, epochs + trained_epochs))\n",
    "    model.fit(x_train, x_train,\n",
    "             epochs=epochs,\n",
    "             batch_size=batch_size)\n",
    "    trained_epochs += epochs\n",
    "    if not os.path.exists('altmodel'):\n",
    "        os.makedirs('altmodel')\n",
    "    path = os.path.join('altmodel', 'altmodel-epoch-%s.h5'%(trained_epochs,))\n",
    "    print(\"Saving snapshot as %s\"%path)\n",
    "    model.save(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: epoch 210 -> 220\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 0s 48us/step - loss: 9.5483e-04\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 0s 57us/step - loss: 9.5620e-04\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 0s 64us/step - loss: 9.5454e-04\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 0s 50us/step - loss: 9.5621e-04\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 0s 60us/step - loss: 9.5354e-04\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 0s 68us/step - loss: 9.5418e-04\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 0s 70us/step - loss: 9.5680e-04\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 0s 73us/step - loss: 9.5606e-04\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 0s 67us/step - loss: 9.5411e-04\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 0s 72us/step - loss: 9.5281e-04\n",
      "Saving snapshot as altmodel/altmodel-epoch-220.h5\n",
      "Training: epoch 220 -> 230\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 0s 80us/step - loss: 9.5081e-04\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 0s 83us/step - loss: 9.5267e-04\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 0s 88us/step - loss: 9.5183e-04\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 0s 86us/step - loss: 9.5128e-04\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 0s 78us/step - loss: 9.4978e-04\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 0s 83us/step - loss: 9.5055e-04\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 0s 80us/step - loss: 9.4649e-04\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 0s 83us/step - loss: 9.4785e-04\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 0s 92us/step - loss: 9.4856e-04\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 0s 97us/step - loss: 9.4957e-04\n",
      "Saving snapshot as altmodel/altmodel-epoch-230.h5\n",
      "Training: epoch 230 -> 240\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 0s 96us/step - loss: 9.4818e-04\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 0s 91us/step - loss: 9.4760e-04\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 0s 90us/step - loss: 9.4544e-04\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 0s 73us/step - loss: 9.4664e-04\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 0s 74us/step - loss: 9.4579e-04\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 0s 78us/step - loss: 9.4745e-04\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 0s 77us/step - loss: 9.4658e-04\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 0s 85us/step - loss: 9.4577e-04\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 0s 104us/step - loss: 9.4930e-04\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 0s 82us/step - loss: 9.5044e-04\n",
      "Saving snapshot as altmodel/altmodel-epoch-240.h5\n",
      "Training: epoch 240 -> 250\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 0s 75us/step - loss: 9.4672e-04\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 0s 66us/step - loss: 9.4309e-04\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 0s 87us/step - loss: 9.4162e-04\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 0s 72us/step - loss: 9.4020e-04\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 0s 76us/step - loss: 9.3995e-04\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 0s 71us/step - loss: 9.4364e-04\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 0s 77us/step - loss: 9.4135e-04\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 0s 83us/step - loss: 9.4023e-04\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 0s 70us/step - loss: 9.3809e-04\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 0s 85us/step - loss: 9.4332e-04\n",
      "Saving snapshot as altmodel/altmodel-epoch-250.h5\n",
      "Training: epoch 250 -> 260\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 0s 77us/step - loss: 9.4141e-04\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 0s 94us/step - loss: 9.3946e-04\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 0s 88us/step - loss: 9.4175e-04\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 0s 80us/step - loss: 9.4145e-04\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 0s 81us/step - loss: 9.4006e-04\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 0s 77us/step - loss: 9.3938e-04\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 0s 72us/step - loss: 9.4386e-04\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 0s 66us/step - loss: 9.4216e-04\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 0s 79us/step - loss: 9.3954e-04\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 0s 79us/step - loss: 9.3998e-04\n",
      "Saving snapshot as altmodel/altmodel-epoch-260.h5\n",
      "Training: epoch 260 -> 270\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 0s 68us/step - loss: 9.4371e-04\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 0s 80us/step - loss: 9.4169e-04\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 0s 78us/step - loss: 9.3778e-04\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 0s 75us/step - loss: 9.3584e-04\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 0s 77us/step - loss: 9.3632e-04\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 0s 75us/step - loss: 9.3696e-04\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 0s 74us/step - loss: 9.3536e-04\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 0s 80us/step - loss: 9.3359e-04\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 0s 63us/step - loss: 9.3844e-04\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 0s 58us/step - loss: 9.3466e-04\n",
      "Saving snapshot as altmodel/altmodel-epoch-270.h5\n",
      "Training: epoch 270 -> 280\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 0s 57us/step - loss: 9.3867e-04\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 0s 71us/step - loss: 9.3262e-04\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 0s 69us/step - loss: 9.3457e-04\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 0s 72us/step - loss: 9.3726e-04\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 0s 70us/step - loss: 9.3486e-04\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 0s 65us/step - loss: 9.3121e-04\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 0s 72us/step - loss: 9.3181e-04\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 0s 76us/step - loss: 9.2971e-04\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 0s 83us/step - loss: 9.3203e-04\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 0s 82us/step - loss: 9.3697e-04\n",
      "Saving snapshot as altmodel/altmodel-epoch-280.h5\n",
      "Training: epoch 280 -> 290\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 0s 71us/step - loss: 9.4020e-04\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 0s 77us/step - loss: 9.3329e-04\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 0s 77us/step - loss: 9.3185e-04\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 0s 61us/step - loss: 9.3245e-04\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 0s 68us/step - loss: 9.3168e-04\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 0s 68us/step - loss: 9.3211e-04\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 0s 62us/step - loss: 9.3065e-04\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 0s 65us/step - loss: 9.2937e-04\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 0s 65us/step - loss: 9.2865e-04\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 0s 72us/step - loss: 9.2802e-04\n",
      "Saving snapshot as altmodel/altmodel-epoch-290.h5\n",
      "Training: epoch 290 -> 300\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 0s 79us/step - loss: 9.2979e-04\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 0s 78us/step - loss: 9.2615e-04\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 0s 55us/step - loss: 9.2598e-04\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 0s 55us/step - loss: 9.3050e-04\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 0s 61us/step - loss: 9.3072e-04\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 0s 59us/step - loss: 9.3094e-04\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 0s 56us/step - loss: 9.3169e-04\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 52us/step - loss: 9.3347e-04\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 0s 56us/step - loss: 9.2886e-04\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 0s 49us/step - loss: 9.2795e-04\n",
      "Saving snapshot as altmodel/altmodel-epoch-300.h5\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading altmodel/altmodel-epoch-200.h5\n",
      "Generating prediction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((500, 294), (101, 294))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict (epoch):\n",
    "    path = os.path.join('altmodel', 'altmodel-epoch-%s.h5'%(epoch,))\n",
    "    print(\"Loading %s\"%path)\n",
    "    model = load_model(path)\n",
    "    print(\"Generating prediction\")\n",
    "    return map(model.predict, (x_train, x_test))\n",
    "y_train, y_test = predict(200)\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = model.predict(x_train), model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.188041,  0.071757, -0.041727, -0.191469,  0.008376,  0.29926 ,\n",
       "       -0.186761,  0.076401, -0.039019, -0.191926,  0.010706, -0.317276,\n",
       "       -0.176773, -0.078195, -0.001716, -0.1874  , -0.107019,  0.266355,\n",
       "       -0.19355 ,  0.027168,  0.255872, -0.193178,  0.020274, -0.28742 ,\n",
       "       -0.1874  , -0.118797, -0.285778,  0.002345, -0.018081, -0.446181,\n",
       "       -0.139854, -0.006102, -0.403974,  0.001501,  0.021966, -0.43595 ,\n",
       "        0.144545, -0.006102, -0.403974,  0.002345, -0.066678, -0.445537,\n",
       "       -0.129798, -0.059359, -0.40573 , -0.140946,  0.028435, -0.388389,\n",
       "        0.145285,  0.028404, -0.388583,  0.132084, -0.059637, -0.406831,\n",
       "        0.192732,  0.071757, -0.041727,  0.196616,  0.010706, -0.317276,\n",
       "        0.191451,  0.076401, -0.039019,  0.19616 ,  0.008376,  0.29926 ,\n",
       "        0.181463, -0.078195, -0.001712,  0.19209 , -0.118797, -0.286042,\n",
       "        0.197869,  0.020274, -0.28742 ,  0.198237,  0.027142,  0.256007,\n",
       "        0.19209 , -0.107019,  0.26609 ,  0.001707,  0.020511,  0.437536,\n",
       "        0.137851,  0.004251,  0.408247,  0.002345,  0.072133,  0.431312,\n",
       "       -0.13686 ,  0.004259,  0.406332,  0.002345, -0.035484,  0.426571,\n",
       "        0.119201, -0.047896,  0.412154,  0.116169,  0.07029 ,  0.405576,\n",
       "       -0.111479,  0.07029 ,  0.405576, -0.11451 , -0.047896,  0.412154,\n",
       "       -0.      , -0.079406, -0.013809, -0.138883, -0.123187, -0.28625 ,\n",
       "        0.178353, -0.080933, -0.00401 , -0.138883, -0.114234,  0.253518,\n",
       "       -0.173662, -0.080933, -0.004008, -0.183861, -0.123187, -0.28625 ,\n",
       "        0.188552, -0.123187, -0.286515,  0.188552, -0.114234,  0.253253,\n",
       "       -0.183861, -0.114234,  0.253518, -0.030519,  0.130658,  0.036033,\n",
       "        0.002345,  0.070903, -0.276893, -0.109772,  0.124245,  0.031355,\n",
       "        0.002345,  0.12185 ,  0.193754,  0.114445,  0.124264,  0.031634,\n",
       "        0.165479,  0.052789, -0.262263, -0.160789,  0.052796, -0.262173,\n",
       "       -0.101655,  0.116738,  0.190779,  0.106345,  0.116738,  0.190779,\n",
       "       -0.183861, -0.123187, -0.28625 , -0.175661, -0.080082, -0.00318 ,\n",
       "       -0.183861, -0.114234,  0.253518, -0.183861, -0.086014,  0.302415,\n",
       "       -0.153931,  0.004705,  0.389794, -0.141717,  0.056613,  0.387792,\n",
       "       -0.153769,  0.072766,  0.277219, -0.185846,  0.077788, -0.038483,\n",
       "       -0.160856,  0.053089, -0.25876 , -0.149822,  0.030687, -0.379899,\n",
       "       -0.187486, -0.024256, -0.347802, -0.183861, -0.094951, -0.335138,\n",
       "        0.188552, -0.114265, -0.31396 ,  0.002345, -0.071818, -0.43928 ,\n",
       "       -0.183861, -0.114265, -0.313695, -0.143117,  0.035175, -0.373659,\n",
       "        0.002345,  0.040783, -0.40102 ,  0.147808,  0.035175, -0.373659,\n",
       "        0.154513,  0.030687, -0.379899,  0.192177, -0.024256, -0.347802,\n",
       "        0.188552, -0.094951, -0.335403,  0.188552, -0.114234,  0.253253,\n",
       "        0.180351, -0.080082, -0.003179,  0.188552, -0.123187, -0.286515,\n",
       "        0.165547,  0.053089, -0.25876 ,  0.190536,  0.077788, -0.038483,\n",
       "        0.15843 ,  0.072773,  0.277584,  0.146408,  0.056613,  0.387792,\n",
       "        0.158622,  0.004705,  0.389794,  0.188552, -0.086014,  0.30215 ,\n",
       "       -0.183861, -0.105321,  0.280965, -0.01808 , -0.052722,  0.40967 ,\n",
       "        0.188552, -0.105321,  0.2807  ,  0.112311,  0.073068,  0.403818,\n",
       "        0.002345,  0.074961,  0.428017, -0.109975,  0.072869,  0.402065,\n",
       "       -0.183861, -0.105321,  0.280965, -0.13768 ,  0.068677,  0.380554,\n",
       "       -0.183861, -0.114265, -0.313695, -0.15657 ,  0.040311, -0.347674,\n",
       "        0.188552, -0.105321,  0.2807  ,  0.142371,  0.068677,  0.380554,\n",
       "        0.188552, -0.114265, -0.31396 ,  0.161261,  0.040311, -0.347674])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.90569937e-01,  2.16046330e-02, -2.42814086e-02, -1.83027416e-01,\n",
       "       -5.75248152e-04,  3.04515243e-01, -1.83217198e-01,  6.07237145e-02,\n",
       "       -3.82540114e-02, -1.83499277e-01, -1.13823311e-02, -3.08607608e-01,\n",
       "       -1.74083784e-01, -6.93430454e-02, -3.85557255e-03, -1.81659818e-01,\n",
       "       -9.26676616e-02,  2.62888491e-01, -1.77214965e-01,  5.37756905e-02,\n",
       "        2.89658010e-01, -1.78229228e-01,  3.21672484e-02, -2.69728482e-01,\n",
       "       -1.81090280e-01, -9.46186632e-02, -2.68231452e-01,  3.77157331e-03,\n",
       "       -2.22427957e-02, -4.29328889e-01, -1.35522544e-01, -2.63939966e-02,\n",
       "       -4.06195939e-01, -5.12617640e-04,  4.54471121e-03, -4.19039786e-01,\n",
       "        1.32203668e-01, -2.92866174e-02, -4.10046130e-01,  1.58825703e-03,\n",
       "       -6.69832081e-02, -4.21616077e-01, -1.27337530e-01, -6.67602643e-02,\n",
       "       -4.04059321e-01, -1.36281550e-01, -8.13290011e-04, -3.94701898e-01,\n",
       "        1.35797545e-01,  4.93134093e-03, -3.95223409e-01,  1.30829513e-01,\n",
       "       -6.47926629e-02, -4.07911420e-01,  1.89748287e-01,  2.24832334e-02,\n",
       "       -3.00936736e-02,  1.88733622e-01, -7.21360371e-03, -2.99545795e-01,\n",
       "        1.85802177e-01,  6.18798211e-02, -3.95606384e-02,  1.86052516e-01,\n",
       "       -3.69463116e-04,  3.05189848e-01,  1.76283240e-01, -7.31266961e-02,\n",
       "       -1.20681636e-02,  1.83994919e-01, -9.18290243e-02, -2.64804929e-01,\n",
       "        1.86849222e-01,  2.59705745e-02, -2.71114945e-01,  1.80007786e-01,\n",
       "        5.14383540e-02,  2.90307611e-01,  1.85560942e-01, -9.50875729e-02,\n",
       "        2.65156686e-01, -7.41815381e-03,  2.43389048e-04,  4.21209395e-01,\n",
       "        1.45730406e-01,  1.85029954e-03,  4.04973090e-01, -3.96796735e-03,\n",
       "        7.25987703e-02,  4.09256101e-01, -1.42065346e-01,  8.77492130e-04,\n",
       "        4.02380884e-01, -1.98469125e-03, -5.50434925e-02,  4.09896731e-01,\n",
       "        1.37411773e-01, -5.34951314e-02,  3.95802945e-01,  1.38727918e-01,\n",
       "        7.35930651e-02,  3.96024346e-01, -1.39644042e-01,  7.41339326e-02,\n",
       "        3.96465987e-01, -1.34514183e-01, -5.27277552e-02,  3.95895779e-01,\n",
       "        3.51861678e-03, -7.63533264e-02, -1.04392879e-02, -5.85044920e-03,\n",
       "       -9.68048424e-02, -2.73534536e-01,  1.70462057e-01, -8.03478509e-02,\n",
       "       -1.01215579e-02, -3.69772427e-02, -1.00301802e-01,  2.63442457e-01,\n",
       "       -1.67297080e-01, -8.05289745e-02, -1.34731457e-02, -1.72575191e-01,\n",
       "       -1.00086711e-01, -2.55825639e-01,  1.77416846e-01, -1.01507075e-01,\n",
       "       -2.55771995e-01,  1.78404436e-01, -1.00469656e-01,  2.53004283e-01,\n",
       "       -1.74947888e-01, -9.90119278e-02,  2.52596676e-01, -8.52947123e-04,\n",
       "        1.29328877e-01,  2.46557016e-02, -4.44662943e-03,  7.82495663e-02,\n",
       "       -1.85622320e-01, -1.01650946e-01,  1.20962918e-01,  3.17645520e-02,\n",
       "       -1.02294376e-03,  1.10878453e-01,  2.39073515e-01,  1.05021536e-01,\n",
       "        1.20950490e-01,  2.94912346e-02,  1.54059529e-01,  5.70200868e-02,\n",
       "       -2.17190444e-01, -1.50111794e-01,  5.95310219e-02, -2.20794991e-01,\n",
       "       -1.27015218e-01,  9.94460136e-02,  2.43606746e-01,  1.26001403e-01,\n",
       "        1.02971107e-01,  2.49794215e-01, -1.77249700e-01, -9.94428694e-02,\n",
       "       -2.52445877e-01, -1.72170684e-01, -8.16790909e-02, -1.84037648e-02,\n",
       "       -1.77945703e-01, -9.97208431e-02,  2.52078652e-01, -1.67956263e-01,\n",
       "       -5.90812080e-02,  3.60402286e-01, -1.66262642e-01,  2.39650346e-03,\n",
       "        3.87880951e-01, -1.56906605e-01,  6.67805374e-02,  3.81301671e-01,\n",
       "       -1.56067386e-01,  8.36220533e-02,  2.60273337e-01, -1.67365670e-01,\n",
       "        8.85880291e-02, -2.72452421e-02, -1.72042608e-01,  5.05104586e-02,\n",
       "       -2.24798173e-01, -1.63400248e-01,  1.47109013e-02, -3.57257277e-01,\n",
       "       -1.66656867e-01, -2.33047642e-02, -3.74819160e-01, -1.60807177e-01,\n",
       "       -6.66287318e-02, -3.74163747e-01,  1.46879509e-01, -7.57013932e-02,\n",
       "       -3.86226833e-01, -1.96072366e-03, -7.21489713e-02, -4.20378417e-01,\n",
       "       -1.42605141e-01, -7.58526176e-02, -3.86551350e-01, -1.52989015e-01,\n",
       "        3.16066109e-02, -3.40790302e-01, -1.09812617e-03,  2.71620583e-02,\n",
       "       -3.74692738e-01,  1.51901573e-01,  3.23369391e-02, -3.44762474e-01,\n",
       "        1.70170650e-01,  1.58670116e-02, -3.51478517e-01,  1.68208376e-01,\n",
       "       -2.43107397e-02, -3.76066238e-01,  1.65650174e-01, -6.70867786e-02,\n",
       "       -3.73083025e-01,  1.82813391e-01, -9.95176435e-02,  2.50503808e-01,\n",
       "        1.74037516e-01, -7.76710734e-02, -2.71955617e-02,  1.79404035e-01,\n",
       "       -9.82166678e-02, -2.55080789e-01,  1.72184825e-01,  4.88232188e-02,\n",
       "       -2.22907767e-01,  1.66584700e-01,  8.66082609e-02, -2.90511809e-02,\n",
       "        1.61403239e-01,  8.42851847e-02,  2.60974139e-01,  1.58239707e-01,\n",
       "        6.42204881e-02,  3.81781310e-01,  1.70276210e-01,  1.78979337e-03,\n",
       "        3.86558771e-01,  1.73086494e-01, -5.99440709e-02,  3.56690764e-01,\n",
       "       -1.48749903e-01, -7.22739995e-02,  3.59459281e-01, -5.00336662e-03,\n",
       "       -5.93420379e-02,  4.04736221e-01,  1.55092344e-01, -6.92075714e-02,\n",
       "        3.59939277e-01,  1.40829116e-01,  7.44962245e-02,  3.90784442e-01,\n",
       "        2.12564133e-03,  7.46225864e-02,  4.06410336e-01, -1.39903009e-01,\n",
       "        7.31967464e-02,  3.92510355e-01, -1.79628626e-01, -8.61624256e-02,\n",
       "        2.98011988e-01, -1.52217612e-01,  6.77168742e-02,  3.74174953e-01,\n",
       "       -1.69327363e-01, -8.55343267e-02, -3.31722170e-01, -1.66259930e-01,\n",
       "        3.78276631e-02, -3.23181629e-01,  1.79944590e-01, -8.45502764e-02,\n",
       "        2.97651500e-01,  1.56036928e-01,  6.96540028e-02,  3.74160737e-01,\n",
       "        1.74117118e-01, -8.36487114e-02, -3.30611706e-01,  1.68222353e-01,\n",
       "        3.90516929e-02, -3.23364794e-01], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.34488608e-02,  6.98919507e-01,  4.18088800e-01,  4.40885132e-02,\n",
       "        1.06867815e+00, -1.75607919e-02,  1.89750662e-02,  2.05197386e-01,\n",
       "        1.96055403e-02,  4.39061063e-02,  2.06317309e+00,  2.73212973e-02,\n",
       "        1.52128197e-02,  1.13203589e-01, -1.24683715e+00,  3.06306420e-02,\n",
       "        1.34100846e-01,  1.30146190e-02,  8.43969764e-02, -9.79376122e-01,\n",
       "       -1.32042623e-01,  7.73834098e-02, -5.86625650e-01,  6.15528433e-02,\n",
       "        3.36697950e-02,  2.03526493e-01,  6.13992277e-02, -6.08346825e-01,\n",
       "       -2.30175083e-01,  3.77696750e-02,  3.09712673e-02, -3.32546649e+00,\n",
       "       -5.50020196e-03,  1.34151742e+00,  7.93102467e-01,  3.87893431e-02,\n",
       "        8.53805503e-02, -3.79951121e+00, -1.50309931e-02,  3.22704891e-01,\n",
       "       -4.57734276e-03,  5.36900921e-02,  1.89561453e-02, -1.24686473e-01,\n",
       "        4.11771205e-03,  3.30938804e-02,  1.02860172e+00, -1.62540600e-02,\n",
       "        6.53023690e-02,  8.26385688e-01, -1.70887788e-02,  9.49764489e-03,\n",
       "       -8.64507413e-02, -2.65569701e-03,  1.54811489e-02,  6.86675399e-01,\n",
       "        2.78796136e-01,  4.00902143e-02,  1.67379074e+00,  5.58825920e-02,\n",
       "        2.95053220e-02,  1.90065299e-01, -1.38814006e-02,  5.15267328e-02,\n",
       "        1.04410973e+00, -1.98150369e-02,  2.85444398e-02,  6.48162152e-02,\n",
       "       -6.04916098e+00,  4.21421258e-02,  2.27008895e-01,  7.42445882e-02,\n",
       "        5.56922935e-02, -2.80979307e-01,  5.67290188e-02,  9.19566703e-02,\n",
       "       -8.95157098e-01, -1.33983099e-01,  3.39895794e-02,  1.11488867e-01,\n",
       "        3.50751135e-03,  5.34572572e+00,  9.88133731e-01,  3.73148840e-02,\n",
       "       -5.71588603e-02,  5.64737818e-01,  8.01943506e-03,  2.69209695e+00,\n",
       "       -6.45710369e-03,  5.11367626e-02, -3.80340950e-02,  7.93967568e-01,\n",
       "        9.72386203e-03,  1.84635021e+00, -5.51220056e-01,  3.90890816e-02,\n",
       "       -1.52773661e-01, -1.16901859e-01,  3.96721980e-02, -1.94190518e-01,\n",
       "       -4.69919639e-02,  2.35508355e-02, -2.52648855e-01, -5.46867633e-02,\n",
       "        2.24619135e-02, -1.74693763e-01, -1.00880139e-01,  3.94469564e-02,\n",
       "                   inf,  3.84438652e-02,  2.44022893e-01,  9.57874980e-01,\n",
       "        2.14163488e-01,  4.44208337e-02,  4.42433994e-02,  7.23004314e-03,\n",
       "       -1.52407927e+00,  7.33752564e-01,  1.21961919e-01, -3.91469510e-02,\n",
       "        3.66511951e-02,  4.99209799e-03, -2.36156329e+00,  6.13822906e-02,\n",
       "        1.87522130e-01,  1.06285978e-01,  5.90561428e-02,  1.75991987e-01,\n",
       "        1.07299811e-01,  5.38183869e-02,  1.20492530e-01,  9.82090191e-04,\n",
       "        4.84774495e-02,  1.33253429e-01,  3.63415478e-03,  9.72051931e-01,\n",
       "        1.01725364e-02,  3.15746632e-01,  2.89621724e+00, -1.03614322e-01,\n",
       "        3.29624369e-01,  7.39811077e-02,  2.64162115e-02, -1.30617763e-02,\n",
       "        1.43622335e+00,  9.00414226e-02, -2.33902345e-01,  8.23405448e-02,\n",
       "        2.66650821e-02,  6.77361519e-02,  6.90085793e-02, -8.01509177e-02,\n",
       "        1.71860139e-01,  6.64050745e-02, -1.27566896e-01,  1.57827119e-01,\n",
       "       -2.49473397e-01,  1.48126458e-01, -2.76905457e-01, -1.84836172e-01,\n",
       "        1.17929836e-01, -3.09338108e-01,  3.59581432e-02,  1.92748671e-01,\n",
       "        1.18093008e-01,  1.98696140e-02, -1.99431939e-02, -4.78734743e+00,\n",
       "        3.21726561e-02,  1.27047612e-01,  5.67749674e-03,  8.65041372e-02,\n",
       "        3.13121027e-01, -1.91747387e-01, -8.01114886e-02,  4.90647510e-01,\n",
       "        4.90784577e-03, -1.07182658e-01, -1.79597219e-01,  1.67366236e-02,\n",
       "       -1.49470067e-02, -1.49191288e-01,  6.11273493e-02,  9.94389430e-02,\n",
       "       -1.38839270e-01,  2.92018758e-01, -6.95442399e-02,  4.85701624e-02,\n",
       "        1.31248366e-01, -9.06291979e-02,  5.20614550e-01,  5.95993230e-02,\n",
       "        1.11097006e-01,  3.92165163e-02, -7.76797129e-02,  1.25387236e-01,\n",
       "        2.98282990e-01, -1.16446798e-01,  2.21013253e-01,  3.37492730e-01,\n",
       "       -2.30178471e-01,  1.83612949e+00, -4.60847224e-03,  4.30285541e-02,\n",
       "        2.24386135e-01,  3.36169276e-01, -2.32252189e-01, -6.89786327e-02,\n",
       "        1.01446742e-01,  8.79644233e-02,  1.46828408e+00,  3.33985772e-01,\n",
       "        6.56507455e-02, -2.76952056e-02,  8.06840334e-02,  7.73339481e-02,\n",
       "       -1.01335486e-01,  4.82940280e-01,  7.48106285e-02,  1.24721608e-01,\n",
       "       -2.25674930e-03, -8.12653110e-02,  1.21461591e-01,  2.93458957e-01,\n",
       "       -1.12342541e-01,  3.04351527e-02,  1.28826414e-01,  1.08555150e-02,\n",
       "        3.50066475e-02,  3.01057244e-02, -7.55475359e+00,  4.85169332e-02,\n",
       "        2.02702657e-01,  1.09712269e-01, -4.00963167e-02,  8.03515080e-02,\n",
       "        1.38554001e-01,  1.25704852e-01, -1.13388452e-01,  2.45090535e-01,\n",
       "       -1.87668925e-02, -1.58193076e-01,  5.98372421e-02, -8.08132571e-02,\n",
       "       -1.34377052e-01,  1.54997786e-02, -7.34715847e-02,  6.19597583e-01,\n",
       "        8.29984265e-03,  8.20224967e-02,  3.03089371e-01, -1.80508901e-01,\n",
       "        1.90965442e-01,  3.13774086e-01, -2.79373876e-01,  7.23265121e-01,\n",
       "       -1.25564999e-01,  1.20433011e-02,  1.77455855e-01,  3.42889154e-01,\n",
       "       -2.82291689e-01, -2.53920953e-01, -1.95465118e-02,  3.22758212e-02,\n",
       "        9.35431424e-02,  4.51452930e-03,  5.04808536e-02, -2.72134657e-01,\n",
       "       -4.49774814e-03,  2.37639324e-02,  2.30194249e-02,  1.81906499e-01,\n",
       "       -6.06729963e-02, -1.05589858e-01,  1.39803110e-02,  1.67625291e-02,\n",
       "        7.90468703e-02,  2.51438964e-01, -5.74671898e-02, -6.18888008e-02,\n",
       "        6.16044473e-02,  7.04463688e-02,  4.56500608e-02,  1.97213505e-01,\n",
       "       -6.03900944e-02, -9.59881457e-02, -1.42260551e-02,  1.67998844e-02,\n",
       "        7.65565037e-02,  2.67941089e-01, -5.30376665e-02, -4.31682357e-02,\n",
       "        3.12397873e-02,  6.99195388e-02])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = x_train[0] - y_train[0]\n",
    "delta / x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
